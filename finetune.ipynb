{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "import torchvision.transforms as T\n",
    "from utils import box_cxcywh_to_xyxy, rescale_bboxes, filter_bboxes_from_outputs, plot_results\n",
    "from utils import CLASSES, COLORS\n",
    "\n",
    "torch.set_grad_enabled(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard PyTorch mean-std input image normalization\n",
    "transform = T.Compose([\n",
    "    T.Resize(800),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load an image for a demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('facebookresearch/detr', 'detr_resnet50', pretrained=True)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = 'http://images.cocodataset.org/train2017/000000310645.jpg'\n",
    "im = Image.open(requests.get(url, stream=True).raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean-std normalize the input image (batch-size: 1)\n",
    "img = transform(im).unsqueeze(0)\n",
    "\n",
    "# propagate through the model\n",
    "outputs = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in [0.9, 0.7, 0.0]:\n",
    "  \n",
    "  probas_to_keep, bboxes_scaled = filter_bboxes_from_outputs(outputs,\n",
    "                                                            threshold=threshold)\n",
    "\n",
    "  plot_results(im, probas_to_keep, bboxes_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/\n",
    "\n",
    "!rm -rf detr\n",
    "!git clone https://github.com/woctezuma/detr.git\n",
    "\n",
    "%cd detr/\n",
    "\n",
    "!git checkout finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pretrained weights\n",
    "checkpoint = torch.hub.load_state_dict_from_url(\n",
    "            url='https://dl.fbaipublicfiles.com/detr/detr-r50-e632da11.pth',\n",
    "            map_location='cpu',\n",
    "            check_hash=True)\n",
    "\n",
    "# Remove class weights\n",
    "del checkpoint[\"model\"][\"class_embed.weight\"]\n",
    "del checkpoint[\"model\"][\"class_embed.bias\"]\n",
    "\n",
    "# Save\n",
    "torch.save(checkpoint,\n",
    "           'detr-r50_no-class-head.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the dataset for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose whether to start indexing categories with 0 or with 1.\n",
    "#\n",
    "# NB: convention in COCO dataset is such that the 1st class (person) has ID n°1.\n",
    "#\n",
    "# NB²: this is why we chose to set to 1 the default value of `first_class_index`\n",
    "# in `via2coco.convert()`.\n",
    "\n",
    "first_class_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/\n",
    "\n",
    "!rm -rf VIA2COCO\n",
    "!git clone https://github.com/woctezuma/VIA2COCO\n",
    "\n",
    "%cd VIA2COCO/\n",
    "\n",
    "!git checkout fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download, decompress the data\n",
    "!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.1/balloon_dataset.zip\n",
    "!unzip balloon_dataset.zip > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import convert as via2coco\n",
    "\n",
    "data_path = '/content/VIA2COCO/'\n",
    "\n",
    "for keyword in ['train', 'val']:\n",
    "\n",
    "  input_dir = data_path + 'balloon/' + keyword + '/'\n",
    "  input_json = input_dir + 'via_region_data.json'\n",
    "  categories = ['balloon']\n",
    "  super_categories = ['N/A']\n",
    "  output_json = input_dir + 'custom_' + keyword + '.json'\n",
    "\n",
    "  print('Converting {} from VIA format to COCO format'.format(input_json))\n",
    "\n",
    "  coco_dict = via2coco.convert(\n",
    "      imgdir=input_dir,\n",
    "      annpath=input_json,\n",
    "      categories=categories,\n",
    "      super_categories=super_categories,\n",
    "      output_file_name=output_json,\n",
    "      first_class_index=first_class_index,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /content/data/custom/annotations/\n",
    "\n",
    "!mv /content/VIA2COCO/balloon/train/custom_train.json /content/data/custom/annotations/custom_train.json\n",
    "!mv /content/VIA2COCO/balloon/val/custom_val.json /content/data/custom/annotations/custom_val.json\n",
    "\n",
    "!mkdir -p /content/data/custom/train2017/\n",
    "\n",
    "!mv /content/VIA2COCO/balloon/train/*.jpg /content/data/custom/train2017/\n",
    "\n",
    "!mkdir -p /content/data/custom/val2017/\n",
    "\n",
    "!mv /content/VIA2COCO/balloon/val/*.jpg /content/data/custom/val2017/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the dataset after it was pre-processed for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pycocotools.coco as coco\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir='/content/data/custom/'\n",
    "dataType='train2017'\n",
    "annFile='{}annotations/custom_train.json'.format(dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize COCO api for instance annotations\n",
    "coco=COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display COCO categories and supercategories\n",
    "cats = coco.loadCats(coco.getCatIds())\n",
    "\n",
    "nms=[cat['name'] for cat in cats]\n",
    "print('Categories: {}'.format(nms))\n",
    "\n",
    "nms = set([cat['supercategory'] for cat in cats])\n",
    "print('Super-categories: {}'.format(nms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and display image\n",
    "catIds = coco.getCatIds(catNms=['balloon']);\n",
    "imgIds = coco.getImgIds(catIds=catIds );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = imgIds[np.random.randint(0,len(imgIds))]\n",
    "print('Image n°{}'.format(img_id))\n",
    "\n",
    "img = coco.loadImgs(img_id)[0]\n",
    "\n",
    "img_name = '%s/%s/%s'%(dataDir, dataType, img['file_name'])\n",
    "print('Image name: {}'.format(img_name))\n",
    "\n",
    "I = io.imread(img_name)\n",
    "plt.figure()\n",
    "plt.imshow(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annIds = coco.getAnnIds(imgIds=img['id'], catIds=catIds)\n",
    "anns = coco.loadAnns(annIds)\n",
    "# load and display instance annotations\n",
    "plt.imshow(I)\n",
    "coco.showAnns(anns, draw_bbox=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(I)\n",
    "coco.showAnns(anns, draw_bbox=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(first_class_index in [0, 1])\n",
    "\n",
    "if first_class_index == 0:\n",
    "\n",
    "  # There is one class, balloon, with ID n°0.\n",
    "\n",
    "  num_classes = 1\n",
    "\n",
    "  finetuned_classes = [\n",
    "      'balloon',\n",
    "  ]\n",
    "\n",
    "  # The `no_object` class will be automatically reserved by DETR with ID equal\n",
    "  # to `num_classes`, so ID n°1 here.  \n",
    "\n",
    "else:\n",
    "\n",
    "  # There is one class, balloon, with ID n°1.\n",
    "  #\n",
    "  # However, DETR assumes that indexing starts with 0, as in computer science,\n",
    "  # so there is a dummy class with ID n°0.\n",
    "  # Caveat: this dummy class is not the `no_object` class reserved by DETR.\n",
    "\n",
    "  num_classes = 2\n",
    "\n",
    "  finetuned_classes = [\n",
    "      'N/A', 'balloon',\n",
    "  ]\n",
    "\n",
    "  # The `no_object` class will be automatically reserved by DETR with ID equal\n",
    "  # to `num_classes`, so ID n°2 here.\n",
    "\n",
    "print('First class index: {}'.format(first_class_index))  \n",
    "print('Parameter num_classes: {}'.format(num_classes))\n",
    "print('Fine-tuned classes: {}'.format(finetuned_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/detr/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py \\\n",
    "  --dataset_file \"custom\" \\\n",
    "  --coco_path \"/content/data/custom/\" \\\n",
    "  --output_dir \"outputs\" \\\n",
    "  --resume \"detr-r50_no-class-head.pth\" \\\n",
    "  --num_classes $num_classes \\\n",
    "  --epochs 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.plot_utils import plot_logs\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "log_directory = [Path('outputs/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_of_interest = ('loss', 'mAP',)\n",
    "\n",
    "plot_logs(log_directory,\n",
    "          fields_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_of_interest = ('loss_ce','loss_bbox','loss_giou',)\n",
    "\n",
    "plot_logs(log_directory,\n",
    "          fields_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_of_interest = ('class_error','cardinality_error_unscaled',)\n",
    "\n",
    "plot_logs(log_directory,\n",
    "          fields_of_interest)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('facebookresearch/detr',\n",
    "                       'detr_resnet50',\n",
    "                       pretrained=False,\n",
    "                       num_classes=num_classes)\n",
    "\n",
    "checkpoint = torch.load('outputs/checkpoint.pth',\n",
    "                        map_location='cpu')\n",
    "\n",
    "model.load_state_dict(checkpoint['model'],\n",
    "                      strict=False)\n",
    "\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_finetuned_results(pil_img, prob=None, boxes=None):\n",
    "    plt.figure(figsize=(16,10))\n",
    "    plt.imshow(pil_img)\n",
    "    ax = plt.gca()\n",
    "    colors = COLORS * 100\n",
    "    if prob is not None and boxes is not None:\n",
    "      for p, (xmin, ymin, xmax, ymax), c in zip(prob, boxes.tolist(), colors):\n",
    "          ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                    fill=False, color=c, linewidth=3))\n",
    "          cl = p.argmax()\n",
    "          text = f'{finetuned_classes[cl]}: {p[cl]:0.2f}'\n",
    "          ax.text(xmin, ymin, text, fontsize=15,\n",
    "                  bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_worflow(my_image, my_model):\n",
    "  # mean-std normalize the input image (batch-size: 1)\n",
    "  img = transform(my_image).unsqueeze(0)\n",
    "\n",
    "  # propagate through the model\n",
    "  outputs = my_model(img)\n",
    "\n",
    "  for threshold in [0.9, 0.7]:\n",
    "    \n",
    "    probas_to_keep, bboxes_scaled = filter_bboxes_from_outputs(outputs,\n",
    "                                                              threshold=threshold)\n",
    "\n",
    "    plot_finetuned_results(my_image,\n",
    "                           probas_to_keep, \n",
    "                           bboxes_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With a training image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img_name = '/content/data/custom/train2017/145053828_e0e748717c_b.jpg'\n",
    "im = Image.open(img_name)\n",
    "\n",
    "run_worflow(im,\n",
    "            model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With a validation image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img_name = '/content/data/custom/val2017/410488422_5f8991f26e_b.jpg'\n",
    "im = Image.open(img_name)\n",
    "\n",
    "run_worflow(im, model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "539930d662aeba406f3d0748c104eece9ce393399656529badbbad4b1587b789"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
